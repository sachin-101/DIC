{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "DEVICE : cuda\n                 id                        sent\n0  BAC009S0002W0122     而 对 楼市 成交 抑制 作用 最 大 的 限\n1  BAC009S0002W0123             也 成为 地方 政府 的 眼中\n2  BAC009S0002W0124  自 六月 底 呼和浩特 市 率先 宣布 取消 限 购\n3  BAC009S0002W0125                  各地 政府 便 纷纷\n4  BAC009S0002W0126              仅 一 个 多 月 的 时间\nNumber of chars 4256\n\nTeacher forcing ratio: 1.0\nTraining, Logging: Mean loss of previous 40 batches \n\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-541edcb290cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTeacher forcing ratio:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                    \u001b[0;31m# Decrease learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'las_model_{epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DIC/Code/Speech_To_Text/LAS Model/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, print_interval, writer, log_interval)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/acnn/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/acnn/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'LAS Model'))\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data import SpeechDataset, AudioDataLoader\n",
    "from listener import Listener\n",
    "from attend_and_spell import AttendAndSpell\n",
    "from seq2seq import Seq2Seq\n",
    "from utils import  train\n",
    "\n",
    "\n",
    "\n",
    "def get_chars(lang, train_df=None):\n",
    "\n",
    "    if lang=='eng':\n",
    "        chars = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', \\\n",
    "                'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \\\n",
    "                'y', 'z', ' ', \"'\", '<eos>', '<pad>']\n",
    "    elif lang=='chinese':\n",
    "        chars = [' ', '<sos>']\n",
    "        for idx in range(train_df.shape[0]):\n",
    "            _, sent = train_df.iloc[idx]\n",
    "            for c in sent:\n",
    "                if c not in chars:\n",
    "                    chars.append(c)\n",
    "        chars = chars + ['<eos>', '<pad>', '<unk>']        \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    print('Number of chars', len(chars))\n",
    "    return chars\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    dataset_dir = '../../../Dataset/data_aishell'\n",
    "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "    print('DEVICE :', DEVICE)\n",
    "    \n",
    "    # data = []\n",
    "    # files = os.listdir(dataset_dir)\n",
    "    # for f in files:\n",
    "    #     if '.txt' in f:\n",
    "    #         with open(os.path.join(dataset_dir, f), 'r') as text:\n",
    "    #             data.append((f.replace('.txt', ''), text.readline()))\n",
    "                \n",
    "    # train_df = pd.DataFrame(data, columns=['id', 'sent'])\n",
    "    # train_df.to_csv(os.path.join(dataset_dir, 'train_df.csv'), header=None)\n",
    "    # print(train_df.head())\n",
    "\n",
    "    # read the transcript\n",
    "    # transcript_dir = '../../../Dataset'\n",
    "    # with open(os.path.join(transcript_dir, 'aishell_transcript_v0.8.txt')) as f:\n",
    "    #     data_list = f.readlines()\n",
    "\n",
    "    # data = []\n",
    "    # for example in data_list:\n",
    "    #     id_, sent = str(example.split(' ')[0]), str(' '.join(example.split(' ')[1:-1])) # -1 to remove '\\n'\n",
    "    #     data.append((id_, sent))\n",
    "\n",
    "    # print('Num examples:', len(data))\n",
    "    # data_df = pd.DataFrame(data, columns=['id', 'sent'])\n",
    "    # data_df.to_csv(os.path.join(transcript_dir, 'data_aishell', 'train_df.csv'))\n",
    "\n",
    "\n",
    "     \n",
    "    train_df = pd.read_csv(os.path.join(dataset_dir, 'train_df.csv'), names=['id', 'sent'])\n",
    "    train_df = train_df.dropna(how='any')\n",
    "    print(train_df.head())\n",
    "    # test_df = pd.read_csv('test_df.csv', names=['id', 'sent'])\n",
    "    \n",
    "    \n",
    "    chars = get_chars('chinese', train_df)\n",
    "    char_to_token = {c:i for i,c in enumerate(chars)} \n",
    "    token_to_char = {i:c for c,i in char_to_token.items()}\n",
    "    sos_token = char_to_token['<sos>']\n",
    "    eos_token = char_to_token['<eos>']\n",
    "    pad_token = char_to_token['<pad>']\n",
    "   \n",
    "    tensorboard_dir = os.path.join('tb_summary')\n",
    "    train_dataset = SpeechDataset(train_df, dataset_dir, sos_token, char_to_token, eos_token)\n",
    "    train_loader = AudioDataLoader(pad_token, train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "    #test_dataset = SpeechDataset(test_df, dataset_dir)\n",
    "    #test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    input_size = 128    # num rows in instagram\n",
    "    hidden_dim = 64    # 256*2 nodes in each LSTM\n",
    "    num_layers = 3\n",
    "    dropout = 0.1\n",
    "    layer_norm = False   \n",
    "    encoder = Listener(input_size, hidden_dim, num_layers, dropout=dropout, layer_norm=layer_norm)\n",
    "\n",
    "    hid_sz = 64\n",
    "    embed_dim = 15\n",
    "    vocab_size = len(chars)\n",
    "    decoder = AttendAndSpell(embed_dim, hid_sz, encoder.output_size, vocab_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = Seq2Seq(encoder, decoder, criterion, tf_ratio = 1.0, device=DEVICE).to(DEVICE)\n",
    "\n",
    "\n",
    "    # Let's start training\n",
    "    epochs = 20\n",
    "    # optimizer = optim.ASGD(model.parameters(), lr=0.2)  # lr = 0.2 used in paper\n",
    "    optimizer = optim.Adadelta(model.parameters())\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.98)\n",
    "    log_interval = 5\n",
    "    print_interval = 40\n",
    "\n",
    "    time = str(datetime.datetime.now())\n",
    "    save_dir = os.path.join('Trained Models', f'Training_{time}')\n",
    "    os.mkdir(save_dir)\n",
    "    summary_dir = os.path.join(tensorboard_dir, time)\n",
    "    writer = SummaryWriter(summary_dir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nTeacher forcing ratio:\", model.tf_ratio)\n",
    "        train(model, DEVICE, train_loader, optimizer, epoch, print_interval, writer, log_interval)\n",
    "        scheduler.step()                                    # Decrease learning rate\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f'las_model_{epoch}'))\n",
    "        model.tf_ratio = max(model.tf_ratio - 0.01, 0.8)    # Decrease teacher force ratio                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}