{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NAME = 'checking_gpu' # helps to differentiate between various training instances\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models.las_model.data import SpeechDataset, AudioDataLoader\n",
    "from models.las_model.listener import Listener\n",
    "from models.las_model.attend_and_spell import AttendAndSpell\n",
    "from models.las_model.seq2seq import Seq2Seq\n",
    "#from models.las_model.utils import  train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-16GB\n",
      "Tesla P100-PCIE-16GB\n",
      "Tesla P100-PCIE-16GB\n",
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-32GB\n",
      "Tesla V100-PCIE-16GB\n",
      "Tesla P100-PCIE-16GB\n",
      "Tesla P100-PCIE-16GB\n",
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE : cuda:3\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:3') if torch.cuda.is_available() else 'cpu'\n",
    "print('DEVICE :', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training examples: 1251\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sin_2241_0329430812.wav</td>\n",
       "      <td>කෝකටත් මං වෙනදා තරම් කාලෙ ගන්නැතිව ඇඳ ගත්තා</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sin_2241_0598895166.wav</td>\n",
       "      <td>ඇන්ජලීනා ජොලී කියන්නේ පසුගිය දිනවල බොහෝ සෙයින්...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sin_2241_0701577369.wav</td>\n",
       "      <td>ආර්ථික චින්තනය හා සාමාජීය දියුණුව ඇති කළ හැකිව...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sin_2241_0715400935.wav</td>\n",
       "      <td>ඉන් අදහස් වන්නේ විචාරාත්මක විනිවිද දැකීමෙන් තො...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sin_2241_0817100025.wav</td>\n",
       "      <td>අප යුද්ධයේ පළමු පියවරේදීම පරාද වී අවසානය</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path                                               sent\n",
       "0  sin_2241_0329430812.wav        කෝකටත් මං වෙනදා තරම් කාලෙ ගන්නැතිව ඇඳ ගත්තා\n",
       "1  sin_2241_0598895166.wav  ඇන්ජලීනා ජොලී කියන්නේ පසුගිය දිනවල බොහෝ සෙයින්...\n",
       "2  sin_2241_0701577369.wav  ආර්ථික චින්තනය හා සාමාජීය දියුණුව ඇති කළ හැකිව...\n",
       "3  sin_2241_0715400935.wav  ඉන් අදහස් වන්නේ විචාරාත්මක විනිවිද දැකීමෙන් තො...\n",
       "4  sin_2241_0817100025.wav           අප යුද්ධයේ පළමු පියවරේදීම පරාද වී අවසානය"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '../../../Dataset/sinhala_clean'\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "\n",
    "\n",
    "# reading the main transcript\n",
    "lines = []\n",
    "with open(os.path.join(root_dir, 'si_lk.lines.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "examples = []\n",
    "for l in lines:\n",
    "    id_, sent, _ = l.split('\"')\n",
    "    id_ = id_.replace(\"(\", '').strip()\n",
    "    sent = sent.strip()\n",
    "    examples.append((id_+'.wav',sent))\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(examples, columns=['path', 'sent'])\n",
    "data_df.to_csv(os.path.join(root_dir, 'data_df.csv')) # save\n",
    "print(\"Number of Training examples:\", data_df.shape[0])\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried removing all the unnecessary characters from the dataset. The others will be replaced by unknown token, while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training example: (1125, 2)\n",
      "Num validation example (126, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>sin_9228_3395907889.wav</td>\n",
       "      <td>මෙන්න කෙනෙක් දැන් මගෙත් එක්ක ඔට්ටු අල්ලන්ට ආවා</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>sin_7183_1886625053.wav</td>\n",
       "      <td>අනෙක් එවැනි ම රටක් වනුයේ බොලීවියාවයි</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>sin_2282_3763216109.wav</td>\n",
       "      <td>එදාට ඇය නවකතා පොතක් අස්සෙ දාල ලියුමක් එවනවා</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>sin_9228_7175568893.wav</td>\n",
       "      <td>අලුත්ම චරිතය තමයි මාදුළුවාවේ සෝභිත හාමුදුරුවෝ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>sin_2241_6534612621.wav</td>\n",
       "      <td>මේ පිළීබඳව ජනයාගේ විරෝධය විවේචනය පැන නැඟූහ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         path                                            sent\n",
       "1179  sin_9228_3395907889.wav  මෙන්න කෙනෙක් දැන් මගෙත් එක්ක ඔට්ටු අල්ලන්ට ආවා\n",
       "1055  sin_7183_1886625053.wav            අනෙක් එවැනි ම රටක් වනුයේ බොලීවියාවයි\n",
       "161   sin_2282_3763216109.wav     එදාට ඇය නවකතා පොතක් අස්සෙ දාල ලියුමක් එවනවා\n",
       "1218  sin_9228_7175568893.wav   අලුත්ම චරිතය තමයි මාදුළුවාවේ සෝභිත හාමුදුරුවෝ\n",
       "72    sin_2241_6534612621.wav      මේ පිළීබඳව ජනයාගේ විරෝධය විවේචනය පැන නැඟූහ"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_df = pd.read_csv(os.path.join(root_dir, 'data_df.csv'), usecols=['path', 'sent'])\n",
    "train_df, val_df = train_test_split(data_df, test_size=0.1)\n",
    "print(\"Num training example:\", train_df.shape)\n",
    "print(\"Num validation example\", val_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(4, 20)(torch.randint(0,4,(32,))).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 70\n",
      "['<pad>', '<unk>', '<sos>', '<eos>', 'ම', 'ෙ', 'න', '්', ' ', 'ක', 'ද', 'ැ', 'ග', 'ත', 'එ', 'ඔ', 'ට', 'ු', 'අ', 'ල', 'ආ', 'ව', 'ා', 'ි', 'ර', 'ය', 'ේ', 'බ', 'ො', 'ී', 'ඇ', 'ප', 'ස', 'ච', 'ළ', 'ෝ', 'භ', 'හ', 'ඳ', 'ජ', 'ධ', 'ඟ', 'ූ', 'ං', 'ඉ', 'ඬ', 'ණ', 'ඒ', 'ඹ', 'ඝ', 'ෂ', 'ඨ', 'ශ', 'උ', 'ථ', 'ෑ', 'ෞ', 'ඩ', 'ඕ', 'ඈ', 'ඓ', 'ඵ', 'ඊ', 'ඡ', 'ඛ', 'ඤ', 'ෆ', 'ෛ', 'ඌ', 'ඪ']\n"
     ]
    }
   ],
   "source": [
    "def get_chars(train_df):\n",
    "    chars = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "    for idx in range(train_df.shape[0]):\n",
    "        id_, sent = train_df.iloc[idx]\n",
    "        for c in sent:\n",
    "            if c not in chars:\n",
    "                chars.append(c)\n",
    "    return chars\n",
    "    \n",
    "\n",
    "chars = get_chars(train_df)\n",
    "char_to_token = {c:i for i,c in enumerate(chars)} \n",
    "token_to_char = {i:c for c,i in char_to_token.items()}\n",
    "sos_token = char_to_token['<sos>']\n",
    "eos_token = char_to_token['<eos>']\n",
    "pad_token = char_to_token['<pad>']\n",
    "unk_token = char_to_token['<unk>']\n",
    "\n",
    "print(\"Number of characters:\", len(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Listener(\n",
       "    (layers): ModuleList(\n",
       "      (0): piBLSTM(\n",
       "        (lstm): LSTM(128, 768, batch_first=True, bidirectional=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): piBLSTM(\n",
       "        (lstm): LSTM(3072, 768, batch_first=True, bidirectional=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): piBLSTM(\n",
       "        (lstm): LSTM(3072, 768, batch_first=True, bidirectional=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): piBLSTM(\n",
       "        (lstm): LSTM(3072, 768, batch_first=True, bidirectional=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): AttendAndSpell(\n",
       "    (attention_layer): Attention(\n",
       "      (linear1): Linear(in_features=3840, out_features=1920, bias=True)\n",
       "      (linear2): Linear(in_features=1920, out_features=1, bias=True)\n",
       "    )\n",
       "    (pre_lstm_cell): LSTMCell(3142, 768)\n",
       "    (post_lstm_cell): LSTMCell(3840, 768)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=70, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 128    # num rows in instagram\n",
    "hidden_dim = 768  # 256*2 nodes in each LSTM\n",
    "num_layers = 4\n",
    "dropout = 0.1\n",
    "layer_norm = False   \n",
    "encoder = Listener(input_size, hidden_dim, num_layers, dropout=dropout, layer_norm=layer_norm)\n",
    "\n",
    "hid_sz = 768\n",
    "vocab_size = len(chars)\n",
    "decoder = AttendAndSpell(hid_sz, encoder.output_size, vocab_size)\n",
    "\n",
    "hyperparams = {'input_size':input_size, 'hidden_dim':hidden_dim, \n",
    "               'num_layers':num_layers,'dropout':dropout, \n",
    "               'layer_norm':layer_norm, 'hid_sz':hid_sz, \n",
    "                'vocab_size':vocab_size}\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, tf_ratio = 1.0, device=DEVICE).to(DEVICE)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(save_dir, 'las_model_1')))\n",
    "# model.train()\n",
    "\n",
    "# load = False\n",
    "# if load:\n",
    "#     saved_file = 'Trained Models/Training_2019-12-25 00:09:23.921978/las_model_6'\n",
    "#     model.load_state_dict(torch.load(saved_file))\n",
    "#     start_epoch = int(saved_file[-1]) + 1\n",
    "#     time = os.listdir(tensorboard_dir)[-1]  # use the last one \n",
    "\n",
    "time = str(datetime.datetime.now())\n",
    "save_dir = os.path.join('trained_models', f'{NAME}_{time}')\n",
    "try:    \n",
    "    os.mkdir(save_dir);\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Saving hyperparmas\n",
    "with open(os.path.join(save_dir, 'info.pickle'), 'wb') as f:\n",
    "    pickle.dump(hyperparams, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, \n",
    "          print_interval, writer=None, log_interval=-1, scheduler=None):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    date1 = datetime.datetime.now()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        loss, _ = model(data, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss.append(loss.detach().item())    # update running loss\n",
    "        \n",
    "        # Writing to tensorboard\n",
    "        if (batch_idx+1) % log_interval == 0:\n",
    "            if writer:\n",
    "                global_step = epoch * len(train_loader) + batch_idx\n",
    "                writer.add_scalar('Loss', np.mean(running_loss[-log_interval:]), global_step)\n",
    "                \n",
    "    # After epoch ends           \n",
    "    date2 = datetime.datetime.now()\n",
    "    print('Epoch: {}\\tMean Loss : {:.6f}\\t lr {}\\t time {}:'.format(\n",
    "        epoch, np.mean(running_loss[-print_interval:]), \n",
    "        optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "        date2 - date1))\n",
    "    \n",
    "\n",
    "    \n",
    "def decode_pred_sent(out):\n",
    "    pred_sent = []\n",
    "    out = out.squeeze(0)\n",
    "    for t in out:\n",
    "        lol = t.max(dim=0)[1].item()\n",
    "        pred_sent.append(token_to_char[lol])\n",
    "    return ''.join(pred_sent)\n",
    "\n",
    "\n",
    "def decode_true_sent(y):\n",
    "    sent = []\n",
    "    for t in y:\n",
    "        sent.append(token_to_char[t.item()])\n",
    "    return ''.join(sent)\n",
    "\n",
    "def validate_personal(model, num_sent, dataset, show=False):\n",
    "    model.eval()\n",
    "    for _ in range(num_sent):\n",
    "        idx = random.randint(0, dataset.__len__())\n",
    "\n",
    "        x, y = dataset.__getitem__(idx)\n",
    "        plt.imshow(x[0,:,:].detach().log2())\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        target = y.unsqueeze(dim=0).to(DEVICE)\n",
    "        data = x.permute(0, 2, 1).to(DEVICE)\n",
    "        loss, output = model(data, target)\n",
    "        print(\"\\n\")\n",
    "        print(\"True sent : \", decode_true_sent(y))\n",
    "        print(\"Pred sent : \", decode_pred_sent(output))\n",
    "        print(\"Loss :\", loss.item())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_loader(model):\n",
    "#     train_dataset = SpeechDataset(train_df, data_dir, char_to_token, n_fft=2048, hop_length=512)\n",
    "    \n",
    "#     if epoch < 3:\n",
    "#         train_loader = train_loader = AudioDataLoader(pad_token, train_dataset, \n",
    "#                                                       batch_size=64, num_workers=8, \n",
    "#                                                       drop_last=True, shuffle=True)\n",
    "#     elif epoch >= 3 and epoch < 5:\n",
    "#         train_loader = train_loader = AudioDataLoader(pad_token, train_dataset, \n",
    "#                                                       batch_size=32, num_workers=8, \n",
    "#                                                       drop_last=True, shuffle=True)\n",
    "#     elif epoch >= 5:\n",
    "#         train_loader = train_loader = AudioDataLoader(pad_token, train_dataset, \n",
    "#                                                       batch_size=8, num_workers=8, \n",
    "#                                                       drop_last=True, shuffle=True)\n",
    "#     return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir trained_models/Adadelta_clean_one_hot_2019-12-31 03:21:10.792257\n",
      "Epoch: 1\tMean Loss : 4.246294\t lr 1.0\t time 0:00:53.842809:\n",
      "Epoch: 2\tMean Loss : 4.241021\t lr 1.0\t time 0:00:52.663319:\n"
     ]
    }
   ],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)  # lr = 0.2 used in paper\n",
    "optimizer = optim.Adadelta(model.parameters())\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), amsgrad=True)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "\n",
    "log_interval = 5\n",
    "print_interval = 50\n",
    "\n",
    "epochs = 100\n",
    "load = False\n",
    "\n",
    "train_dataset = SpeechDataset(train_df, data_dir, char_to_token, n_fft=2048, hop_length=512)\n",
    "train_loader = train_loader = AudioDataLoader(pad_token, train_dataset, \n",
    "                                              batch_size=32, num_workers=8, \n",
    "                                              drop_last=True, shuffle=True)\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "print('save_dir', save_dir)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    # train_loader = get_loader(epoch)\n",
    "    \n",
    "    train(model, DEVICE, train_loader, optimizer, epoch, print_interval, writer, log_interval)\n",
    "    \n",
    "    # Decrease tf_ratio\n",
    "    if epoch % 10 == 0:\n",
    "        model.tf_ratio = model.tf_ratio - 0.05\n",
    "        validate_personal(model, 1, train_dataset)\n",
    "        print(\"tf_ratio\", model.tf_ratio)\n",
    "    # scheduler.step()\n",
    "    \n",
    "    # save model\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f'las_model_{epoch}')) #save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DOES DEEPER NETWORK HELP ?\n",
    "YES\n",
    "\n",
    "### DOES AMSGRAD HELP ?\n",
    "\n",
    "### DOES LAYER NORMALIZATION HELP ?\n",
    "YES, WITH SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_personal(model, 10, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knowing the frequency of words\n",
    "\n",
    "def process(s):\n",
    "    return list(s)\n",
    "\n",
    "si_field = Field(\n",
    "    tokenizer_language='si',\n",
    "    lower=True, \n",
    "    init_token='<sos>', \n",
    "    eos_token='<eos>',\n",
    "    batch_first=True,\n",
    "    preprocessing=process\n",
    ")\n",
    "\n",
    "dataset = TabularDataset(\n",
    "    path=os.path.join(data_dir, 'temp.csv'),\n",
    "    format='CSV',\n",
    "    fields=[('index', None),('unnamed', None), ('sent', si_field)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_field.build_vocab(dataset, min_freq=2)\n",
    "print(len(si_field.vocab.stoi))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
