{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shastra 2020\n",
    "\n",
    "## Translation task (demo)\n",
    "\n",
    "This is Neural machine translation model to convert **French** to **English** text. This is demo model for the end product model, which will be able to convert the any language to multiple languages through advanced version of the Machine translation models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the model is a simple encoder and decoder model:\n",
    "\n",
    "Encoder:\n",
    " 1. Embedding Layer for French language\n",
    " 2. Two LSTM layers <br><br>\n",
    "For demo, purpose the model is simple but in actual implementation the there will be more number of layers with some optimization techniques will be used.\n",
    "It will take French sentences as input and will provide the hidden state at last timestep and outputs at all the timesteps to the decoder to produce the output language with attention.  Here, later on Bidirectional LSTM will be used for better encoding.\n",
    " \n",
    "Decoder:\n",
    " 1. Embedding Layer for English language\n",
    " 2. Two LSTM layers \n",
    " 3. Attention layer\n",
    " 4. Fully connected\n",
    " 5. Softmax layer <br><br>\n",
    "This takes the last hidden state of the encoder and all the outputs of all the timesteps of the encoder and by using [Attention mechanism](https://arxiv.org/abs/1508.04025) with the first input word given it will generate the next word and will use that with attention mechanism to generate succeeding words and hence the sentence will be translated.In this architecture, we also use **Teacher forcing** concept in which based on some random number between \\[0, 1) and a teacher forcing ratio we select whether to input the last output of the deoder as the next input or to input the target output as the next input to the decoder, as it is shown in some research papers that this improves training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is just for testing purpose, to check whether the architecture can work or not. In final model will also contain some other optimization techniques for better convergence and accuracy: (click on any technique to see it's resource)\n",
    "1. [BatchNormalization](https://arxiv.org/abs/1502.03167)\n",
    "2. [Variational DropOut instead of normal DropOut for LSTM layers](https://becominghuman.ai/learning-note-dropout-in-recurrent-networks-part-1-57a9c19a2307)\n",
    "3. [DropConnect for LSTM layers (Variational in nature)](https://arxiv.org/abs/1801.06146)\n",
    "4. [Differential learning rates for different layers](https://arxiv.org/abs/1801.06146)\n",
    "5. [AWD-LSTMs (ASGD Weight-Dropped LSTMs) (tentative)](https://arxiv.org/abs/1708.02182)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: For preparing the dataset first use the **text_to_csv.py** file to convert all the data to csv after extracing the data downloaded from **[here](http://www.statmt.org/europarl/v7/fr-en.tgz)**. After extracting the path variables in the **text_to_csv.py** file have to be changed accordingly. Other datasets can be downloaded from [here](www.statmt.org/europarl/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all the required packages with this \n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn       # neural Networks module of pytorch for extending\n",
    "import torch.optim as optim     # Optimizers\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import spacy    # for French and English tokenization\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset    # For preprocessing and making batches\n",
    "import dill      # for saving field of the datasets\n",
    "import random    # for teaching force in the decoder part\n",
    "import matplotlib.pyplot as plt   # for visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "TEACHER_FORCE_RATIO = 0.5\n",
    "GRADIENT_CLIP = 0.25\n",
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading SpaCy tokenizers for French and English\n",
    "fr_tokenize = spacy.load('fr', disable=['tagger', 'ner', 'parser'])\n",
    "en_tokenize = spacy.load('en', disable=['tagger', 'ner', 'parser'])\n",
    "de_tokenize = spacy.load('de', disable=['tagger', 'ner', 'parser'])\n",
    "\n",
    "fr_field = Field(\n",
    "    tokenize='spacy', \n",
    "    tokenizer_language='fr', \n",
    "    pad_first=True,\n",
    "    lower=True\n",
    ")\n",
    "en_field = Field(\n",
    "    tokenize='spacy', \n",
    "    tokenizer_language='en', \n",
    "    lower=True, \n",
    "    init_token='<sos>', \n",
    "    eos_token='<eos>'\n",
    ")\n",
    "de_field = Field(\n",
    "    tokenize='spacy', \n",
    "    tokenizer_language='de', \n",
    "    lower=True, \n",
    "    init_token='<sos>', \n",
    "    eos_token='<eos>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below can be used to load already saved fields when the fields have been saved by the saving code given below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"fr_field.Field\", \"rb\") as f:\n",
    "#     fr_field = dill.load(f)\n",
    "\n",
    "# with open(\"en_field.Field\", \"rb\") as f:\n",
    "#     en_field = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a torchtext Datasets for **train** and **validation** set for translation using [**TabularDataset**](https://torchtext.readthedocs.io/en/latest/data.html#tabulardataset) class. (this might take some time to get loaded). Set the path to the directory in which the csv files are stored in **path** arguement and set the name of the train and val sets in the **train** and **validation** arguments before running the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = TabularDataset.splits(\n",
    "    path='../data/csv_format/', \n",
    "    train='train_set.csv', \n",
    "    validation='val_set.csv',\n",
    "    format='CSV', \n",
    "    fields=[('French', fr_field), ('English', en_field)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocabularies for the French and English using Fields from the above dataset, with having each word in vocabularies atleast 5 occurances in the whole train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting vocabularies for French and English\n",
    "fr_field.build_vocab(train_set, val_set, min_freq=5)\n",
    "en_field.build_vocab(train_set, val_set, min_freq=5)\n",
    "\n",
    "print(\"Example from French vocabulary:\\n\", list(fr_field.vocab.freqs.keys())[1:100])\n",
    "print(\"Examples from English vocabulary:\\n\", list(en_field.vocab.freqs.keys())[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequence bucketing based on size of English sentences\n",
    "train_iterator, val_iterator = BucketIterator.splits(\n",
    "    (train_set, val_set), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sort_key=lambda x: len(x.English), \n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_iterator))\n",
    "print(batch.French)\n",
    "print(batch.English)\n",
    "print(len(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder for the input language\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_sz, embedding_sz, output_sz, batch_sz, max_len, num_lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.max_len = max_len\n",
    "        self.hidden_sz = output_sz\n",
    "        self.embedding_layer = nn.Embedding(vocab_sz, embedding_sz)\n",
    "        self.lstm = nn.LSTM(embedding_sz, output_sz, num_lstm_layers)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        embeddings = self.embedding_layer(batch)\n",
    "        outputs, hidden = self.lstm(embeddings)\n",
    "        if batch.shape[0]-self.max_len < 0: \n",
    "            return (torch.cat(\n",
    "                (torch.zeros(self.max_len-batch.shape[0], *outputs.shape[1:]).to(DEVICE), outputs), dim=0), \n",
    "                hidden)\n",
    "        else: return outputs[batch.shape[0]-self.max_len:], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder with attention\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_sz, hidden_sz, max_length, num_lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_sz, embedding_sz)\n",
    "        self.attention_layer = nn.Linear(hidden_sz*num_lstm_layers+embedding_sz, max_length)\n",
    "        self.lstm = nn.LSTM(hidden_sz, hidden_sz, num_lstm_layers)\n",
    "        self.linear = nn.Linear(hidden_sz, vocab_sz)\n",
    "        self.bn = nn.BatchNorm1d(vocab_sz)\n",
    "        self.d = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        embeddings = self.embedding_layer(x)\n",
    "        attention_weights = F.softmax(\n",
    "            self.attention_layer(\n",
    "                torch.cat((embeddings, torch.cat(hidden[0].split(1, dim=0), dim=-1).squeeze()), 1)), \n",
    "            1\n",
    "        )\n",
    "        attention_output = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs.permute(1, 0, 2))\n",
    "        output, hidden = self.lstm(attention_output.permute(1, 0, 2))\n",
    "        output = self.linear(output[0])\n",
    "        output = self.bn(output)\n",
    "        return self.d(output), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        X = batch.French\n",
    "        Y = batch.English\n",
    "\n",
    "        if X.shape[1] != BATCH_SIZE : continue\n",
    "\n",
    "        # Forward pass in Encoder part of model\n",
    "        encoder_outputs, hidden = self.encoder(X.to(DEVICE))\n",
    "\n",
    "        # Initializing losses for batchwise\n",
    "        loss = 0.0\n",
    "\n",
    "        # First input to the decoder ,i.e., \"<sos>\" token\n",
    "        dec_input = (Y[0, :]).to(DEVICE)\n",
    "\n",
    "        # Passing the o utput of the decoder to itself as next input or \n",
    "        # target output sometimes bassed on Teacher forcing\n",
    "        for target in Y[1:, :]:\n",
    "            output, hidden = self.decoder(dec_input, hidden, encoder_outputs)\n",
    "            loss += loss_criterion(output, target.to(DEVICE))\n",
    "            dec_input = output.max(dim=1)[1]\n",
    "            teacher_force = random.random() < TEACHER_FORCE_RATIO\n",
    "            dec_input = target.to(DEVICE) if teacher_force else dec_input\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_diff_lrs(model, opt_type=nn.SGD, starting_lr=0.01, dividing_fact=2.6):\n",
    "    i = 0\n",
    "    for module in model.named_parameters():\n",
    "        trainable_modules = []\n",
    "        optimizers = []\n",
    "        if type(module) not in [Seq2seq, Encoder, AttentionDecoder, Dropout]:\n",
    "            trainable_modules.append(module)\n",
    "            if type(module) == BatchNorm1d:\n",
    "                optimizers[-1] = optim.SGD(list(trainable_modules[-2].parameters())+list(module.parameters()), lr=starting_lr/(2.6**i))\n",
    "                continue\n",
    "            optimizers.append(optim.SGD(module.parameters(), lr=starting_lr/(2.6**i)))\n",
    "            i += 1\n",
    "            \n",
    "    return optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize encoder and decoder for the model\n",
    "encoder = Encoder(len(fr_field.vocab.freqs), 256, 512, BATCH_SIZE, 70).to(DEVICE)\n",
    "decoder = AttentionDecoder(len(en_field.vocab.freqs), 256, 512, 70).to(DEVICE)\n",
    "\n",
    "pad_idx = fr_field.vocab.stoi['<pad>']\n",
    "loss_criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizers = apply_diff_lrs(model, nn.SGD, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(10000, 256, 512, 8, 70)\n",
    "decoder = AttentionDecoder(10000, 256, 512, 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell can be used if in case you have saved any models after training with the saving code given below, this code can be used to load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.load_state_dict(torch.load(\"enc_model.pt\"))\n",
    "# decoder.load_state_dict(torch.load(\"dec_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "First number of **batch_sz** sentences will be entered to the **encoder** and the ouptut will be given as initial hidden state for the **decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train(model, train_iterator=train_iterator, optimizer=optimizer, EPOCHS=EPOCHS, DEVICE=DEVICE):\n",
    "    epoch_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        iteration_losses = []\n",
    "        for iter_n, batch in enumerate(train_iterator):\n",
    "            \n",
    "            # Setting all the gradients to zero\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass from the sequence to sequence model\n",
    "            loss = model(batch)\n",
    "\n",
    "            # Backpropagation step\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "\n",
    "            # Updation for the weights\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.step()\n",
    "\n",
    "            # Appending average loss in one iteration for each output token\n",
    "            iteration_losses.append(loss.item()/Y.shape[0])\n",
    "            if (iter_n+1) % 1000 == 0:\n",
    "                print(\"Iterations completed\", iter_n+1, \"Loss:\", loss.item())\n",
    "\n",
    "        epoch_losses.append(sum(iteration_losses)/len(iteration_losses))\n",
    "        print(\"Epoch: \", epoch+1, \"Average Loss:\", sum(iteration_losses)/len(iteration_losses))\n",
    "        plt.plot(range(len(iteration_losses)), iteration_losses)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "\n",
    "    plt.plot(range(EPOCHS), epoch_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(iteration_losses)), iteration_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the saving code (mentioned above) for saving encoder and decoder models and fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Encoder and Decoder and Fields of the torchtext\n",
    "with open(\"enc_model.pt\", \"wb\") as f:\n",
    "    torch.save(encoder.state_dict(), f)\n",
    "    \n",
    "with open(\"dec_model.pt\", \"wb\") as f:\n",
    "    torch.save(decoder.state_dict(), f)\n",
    "    \n",
    "with open(\"fr_field.Field\", \"wb\") as f:\n",
    "    dill.dump(fr_field, f)\n",
    "\n",
    "with open(\"en_field.Field\", \"wb\") as f:\n",
    "    dill.dump(en_field, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "The model can be evaluted on **val_iterator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model\n",
    "def evaluate_model(model, val_iterator=val_iterator, DEVICE=DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _, batch in enumerate(val_iterator):\n",
    "            \n",
    "            X = batch.French\n",
    "            Y = batch.English\n",
    "\n",
    "            encoder_outputs, hidden = model.encoder(X.to(DEVICE))\n",
    "            dec_input = Y[0,:].to(DEVICE)\n",
    "            loss= 0.0\n",
    "            for target in Y[1:, :]:\n",
    "                output, hidden = model.decoder(dec_input, hidden, encoder_outputs)\n",
    "                loss += loss_criterion(output, target.to(DEVICE))\n",
    "                dec_input = output.max(dim=1)[1]\n",
    "                \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    print(epoch_loss / len(val_iterator))\n",
    "\n",
    "# To get the predicted words \n",
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(X.to(DEVICE))\n",
    "        dec_input = Y[0,:].to(DEVICE)\n",
    "        for target in Y[1:, :]:\n",
    "            output, hidden = model.decoder(dec_input, hidden, encoder_outputs)\n",
    "            dec_input = output.max(dim=1)[1]\n",
    "            outputs.append(en_field.vocab.itos(dec_input))\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
